---
title: LLMとツール活用
source: ["x"]
published: 2025-08-28
captured: 2025-08-28
content_tags: ["llm", "tool-use", "agent", "ai-agent", "benchmark", "mcp"]
tags: ["llm", "tool-use", "agent", "ai-agent", "benchmark", "mcp"]
aliases: ["大規模言語モデル", "ツール利用", "エージェント", "AIエージェント", "ベンチマーク", "MCP"]
concepts: ["LLM", "ツールオーケストレーション"]
urls: ["https://x.com/hiro_gamo/status/1961006341142847643","https://arxiv.org/html/2508.15760v1"]
---

# LLMとツール活用
## 原文
GPT-5-thinkingの強さはAgenticなTool-Useの上手さにあるんだよな。Web検索を持っていないOpenAIのモデルなのに検索精度が高いのもこの辺りの能力が鍛えられてるからなんだろうな。この論文はMCP、つまりは初見のToolを
どう使いこなせるかを評価してて、LLMは総じて課題はあるもののGPT-5はやはり強そう。今まで未知のツールの場合はやはり強化学習を施さないとちょっと頼り無いのか…？と思ってたが、これ見ると順当に進化は進んでるから、そのうちよしなにやってくれるようになるんだろうか。

よしなにやってくれるようになったら、Agent自前開発はあまり要らなくなって、基本的にResponses APIにMCPでツール持たせたらそれなりのパフォーマンスが出るかもしれない。

で、それと各種ルールベース含んだ処理をワークフロー化して遷移条件だけ整えたら業務自動化Agent Workflowの完成！めでたしめでたしになるとだいぶ適用進むんだろうけど、夢見すぎか…？
https://t.co/WNsAGeJygW

本論文は、多様なツールを連携して複雑なタスクを解決するAIエージェントの能力を評価するための新しいベンチマークLiveMCP-101を提案する。101個の現実世界のクエリを用いた実験では、最先端のLLMでも成功率が60%未満であり、ツールのオーケストレーションにおける課題が示された。詳細なアブレーションスタディとエラー分析から、モデルの改善に向けた具体的な方向性が示唆されている。LiveMCP-101は、現実世界のエージェント能力を厳格に評価するための基準となる。
                      // 元本文（改行保持）

## 関連概念（内部リンク）
[[LLM]] [[ツールオーケストレーション]]

## 参照
- https://x.com/hiro_gamo/status/1961006341142847643
- https://arxiv.org/html/2508.15760v1